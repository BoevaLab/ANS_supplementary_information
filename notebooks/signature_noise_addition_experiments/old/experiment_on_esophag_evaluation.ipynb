{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "122ff766",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment influence of noise in gene expression signatures on scoring (ESCC)\n",
    "In this experiment we evaluated the robustness of gene signature scoring methods to noise in gene expression signatures on ESCC. We started with base signatures that were able to discriminate malignant vs. non-malignant cells with an AUCROC value of $0.9$ and were shortest. We iteratively added random gene with $-0.25\\le lofFC \\le 0.25$, i.e., non-relevant genes.\n",
    "\n",
    "The scripts to run the experiments can be found in the `experiments/signature_noise_addition_experiments` folder. The experiments evaluate the AUCROC for malignant vs. non-malignant cells and store the performance files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093f734",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553f9bb0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from data.constants import BASE_PATH_EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'pdf.fonttype':42, 'font.family':'sans-serif', 'font.sans-serif':'Arial', 'font.size':14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91c33bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## define path to store visualizations\n",
    "storing_path = os.path.join(BASE_PATH_EXPERIMENTS, 'signature_noise_addition_experiments/esophag')\n",
    "storing_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e760c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aba288",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'median' # methods in ['mean', 'median']\n",
    "factor_ucell = 169 if method == 'mean' else 81\n",
    "factor_rest = 4 # the same for 'mean' or 'median'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7bb4c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluate AUCs for runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74022337",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## define path to AUCROC performance files\n",
    "base_path = storing_path  \n",
    "list_performance_files = glob.glob(os.path.join(base_path, 'AUC_performances/AUC_*.csv'))\n",
    "list_performance_files = [fn for fn in list_performance_files if method in fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c35a8c",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list_performance_files.sort()\n",
    "list_performance_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08338e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list_performances = [pd.read_csv(x) for x in list_performance_files]\n",
    "all_performances = pd.concat(list_performances)\n",
    "all_performances = all_performances.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda8d9f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d68ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_performances.scoring_method = all_performances.scoring_method.apply(lambda x : '_'.join(x.split('_')[0:-3]))\n",
    "all_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f6d51c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# all_performances.loc[all_performances.scoring_method=='ucell_scoring', 'added_non_relevant_genes'] = all_performances.loc[all_performances.scoring_method=='ucell_scoring', 'added_non_relevant_genes']/120\n",
    "all_performances.loc[all_performances.scoring_method=='ucell_scoring', 'added_non_relevant_genes'] = all_performances.loc[all_performances.scoring_method=='ucell_scoring', 'added_non_relevant_genes']/factor_ucell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bcaa90",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# all_performances.loc[all_performances.scoring_method!='ucell_scoring', 'added_non_relevant_genes'] = all_performances.loc[all_performances.scoring_method!='ucell_scoring', 'added_non_relevant_genes']/10\n",
    "all_performances.loc[all_performances.scoring_method!='ucell_scoring', 'added_non_relevant_genes'] = all_performances.loc[all_performances.scoring_method!='ucell_scoring', 'added_non_relevant_genes']/factor_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d32a9c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# perf_ucell = all_performances[all_performances.scoring_method=='ucell_scoring'].copy().reset_index()\n",
    "# perf_ucell = perf_ucell[perf_ucell.added_non_relevant_genes<=22]\n",
    "# perf_not_ucell = all_performances[all_performances.scoring_method.isin(['ucell_scoring','neighborhood_scoring','corrected_scanpy_scoring'])==False].copy().reset_index()\n",
    "# perf_not_ucell = perf_not_ucell[perf_not_ucell.added_non_relevant_genes<51].reset_index()\n",
    "# all_performances = pd.concat([perf_ucell,perf_not_ucell], axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adfc173",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#all_performances = all_performances[all_performances.added_non_relevant_genes<41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d2f89",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_performances.scoring_method.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a807c4",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_performances.scoring_method = all_performances.scoring_method.map({\n",
    "    'adjusted_neighborhood_scoring':'ANS',\n",
    "    'jasmine_lh_scoring':'Jasmine_LH',\n",
    "    'jasmine_or_scoring':'Jasmine_OR',\n",
    "    'scanpy_scoring':'Scanpy',\n",
    "    'tirosh_ag_scoring':'Tirosh_AG',\n",
    "    'tirosh_lvg_scoring':'Tirosh_LVG',\n",
    "    'tirosh_scoring':'Tirosh',\n",
    "    'ucell_scoring':'UCell',\n",
    "})\n",
    "#all_performances.scoring_method = all_performances.scoring_method.map(\n",
    "#{'ucell_scoring':'UCell',\n",
    "# 'adjusted_neighborhood_scoring':'ANS',\n",
    "# 'agcg_scoring':'Tirosh_AG',\n",
    "# 'jasmine_scoring_lh':'Jasmine_LH',\n",
    "# 'jasmine_scoring_or':'Jasmine_OR',\n",
    "# 'lvcg_scoring':'Tirosh_LVG',\n",
    "# 'tirosh_scoring':'Tirosh',\n",
    "# 'original_scanpy_scoring':'Scanpy'\n",
    "#}\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc76c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for group in all_performances.groupby(['scoring_method','added_non_relevant_genes']).mean().reset_index().sort_values(by='added_non_relevant_genes').groupby('added_non_relevant_genes'):\n",
    "    print(group[1].sort_values(by='scoring_method'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c217bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_names = ['ANS', 'Tirosh', 'Tirosh_AG', 'Tirosh_LVG', 'Scanpy', 'Jasmine_LH', 'Jasmine_OR', 'UCell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b83914",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = all_performances.groupby(['scoring_method','added_non_relevant_genes']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7111e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[tmp.AUC<=0.9].groupby('scoring_method').added_non_relevant_genes.min(), tmp[tmp.AUC<=0.9].groupby('scoring_method').AUC.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ed926",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with plt.rc_context({'figure.figsize': (16,8)}):\n",
    "    plt.axvline(3, ls='--', alpha=0.4, c='grey')\n",
    "    plt.axvline(13, ls='--', alpha=0.4, c='grey')\n",
    "    plt.axvline(24, ls='--', alpha=0.4, c='grey')\n",
    "    plt.axhline(0.99, c='r',ls=':',alpha=0.7, label='AUCROC 0.99')\n",
    "    plt.axhline(0.95, c='orange',ls=':',alpha=0.7, label='AUCROC 0.95')\n",
    "    plt.axhline(0.9, c='g',ls=':',alpha=0.7, label='AUCROC 0.90')\n",
    "    \n",
    "    for val in sc_names:\n",
    "        curr_data = all_performances[all_performances.scoring_method==val]\n",
    "        sns.lineplot(data=curr_data, x=\"added_non_relevant_genes\", y=\"AUC\",label=val)\n",
    "\n",
    "    plt.legend(fontsize=16)\n",
    "    plt.title(f'Robustness of scoring methods to signatures containing non-informative genes', fontsize=18)\n",
    "    plt.xticks((np.arange(0, 41)),fontsize=16)\n",
    "    plt.xlabel('Factor of non-informative genes added to base signature', fontsize=16)\n",
    "    plt.ylabel('AUCROC',fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(storing_path,f'evaluation_{method}.svg'), format='svg')\n",
    "        plt.savefig(os.path.join(storing_path,f'evaluation_{method}.png'), format='png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f627d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3460b4b2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparable score ranges experiment - *easy* discrimination task\n",
    "The following notebook explores the comparability of score ranges for the *easy* task when using **non-overlapping** signatures for **three** available cell types (B cells, Monocytes, NK cells).\n",
    "\n",
    "After selecting the cell type specific signatures we score with each scoring method the signatures and apply hard labeling on the scores as well as on the probabilities returned by the GMM postprocessing.\n",
    "\n",
    "This jupyter notebook uses the data and differentially expressed genes found [here](https://atlas.fredhutch.org/nygc/multimodal-pbmc/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a21a80d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score, jaccard_score, balanced_accuracy_score\n",
    "\n",
    "sys.path.append('../../..')\n",
    "from data.load_data import load_datasets\n",
    "from data.constants import BASE_PATH_EXPERIMENTS, BASE_PATH_DATA\n",
    "\n",
    "from signaturescoring import score_signature\n",
    "from signaturescoring.scoring_methods.gmm_postprocessing import GMMPostprocessor\n",
    "from signaturescoring.utils.utils import check_signature_genes, get_mean_and_variance_gene_expression\n",
    "\n",
    "sc.settings.verbosity = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0bc8a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876de414",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'pdf.fonttype':42, 'font.family':'sans-serif', 'font.sans-serif':'Arial', 'font.size':14})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98ad168",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886132d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the path where the PBMC data is stored\n",
    "dataset = 'pbmc_b_mono_nk'\n",
    "norm_method = 'mean'\n",
    "DE_of_celltypes_fn = os.path.join(BASE_PATH_DATA, 'annotations/citeseq_pbmc/DE_by_celltype.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc001e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## define the path where data should be stored.\n",
    "storing_path = os.path.join(BASE_PATH_EXPERIMENTS, 'comparable_score_ranges/B_NK_Mono/scoring_all_overlapping_signatures')\n",
    "if not os.path.exists(storing_path):\n",
    "    os.makedirs(storing_path)\n",
    "    sc.logging.info(f'Created new directory with path {storing_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3969c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ba134d",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52afe559",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = load_datasets(dataset, norm_method=norm_method)\n",
    "if 'log1p' in adata.uns_keys():\n",
    "    adata.uns['log1p']['base'] = None\n",
    "else:\n",
    "    adata.uns['log1p'] = {'base': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb776ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['celltype.l1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9371a51b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get for each celltype in level 1 the set of types in level 3 and the same for celltype level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbb5a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "celltype_sets_l2 = {}\n",
    "for group in  adata.obs[['celltype.l2','celltype.l3']].groupby(by='celltype.l2'):\n",
    "    celltype_sets_l2[group[0]] = list(np.unique(group[1]['celltype.l3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f805ec92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "celltype_sets_l1 = {}\n",
    "for group in  adata.obs[['celltype.l1','celltype.l2']].groupby(by='celltype.l1'):\n",
    "    new_celltype_list = []\n",
    "    for celltype in list(np.unique(group[1]['celltype.l2'])):\n",
    "        new_celltype_list.append(celltype_sets_l2[celltype])\n",
    "    celltype_sets_l1[group[0]] = list(itertools.chain(*new_celltype_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9aa551",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "celltype_sets_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e643810c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Look at the differentially expressed genes given by the paper\n",
    "The differential gene expression is done on level 3 celltypes. The logfoldchanges for the genes of different cell types are not comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b36caf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## define path to table with DGEX genes\n",
    "DE_of_celltypes = pd.read_csv(DE_of_celltypes_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39108388",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "get signatures for celltype level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f879f90",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grouped_DE_of_celltypes = DE_of_celltypes.groupby(by='Cell Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56728bbc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SG_subtypes = {}\n",
    "for key, subtypes in celltype_sets_l1.items():\n",
    "    sig_genes = set()\n",
    "    for subtype in subtypes:\n",
    "        if subtype not in grouped_DE_of_celltypes.groups.keys():\n",
    "            continue\n",
    "        group = grouped_DE_of_celltypes.get_group(subtype)\n",
    "        sig_genes.update(group.sort_values(by='Average Log Fold Change', ascending=False)['Gene'].iloc[0:300])\n",
    "    SG_subtypes[key] = sig_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1dd668",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SG_subtypes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38947f0b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for key, val in SG_subtypes.items():\n",
    "    print(f'signature for subtype {key} has length {len(val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b389af03",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Remove signature genes with too high average expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b9bc6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for key, val in SG_subtypes.items():\n",
    "    print(f'signature for {key} has length {len(val)}')\n",
    "    SG_subtypes[key] = list(val)\n",
    "    SG_subtypes[key]  = check_signature_genes(adata.var_names, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6b978",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'pdf.fonttype':42, 'font.family':'sans-serif', 'font.sans-serif':'Arial', 'font.size':14})\n",
    "df_mean_var = get_mean_and_variance_gene_expression(\n",
    "    adata,\n",
    "    estim_var=True,\n",
    "    show_plots=True,\n",
    "    #store_path=storing_path,\n",
    "    #store_data_prefix='all'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'pdf.fonttype':42, 'font.family':'sans-serif', 'font.sans-serif':'Arial', 'font.size':14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec3c8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k,v in SG_subtypes.items():\n",
    "    print(f'Signature for subtype {k} contains {len(v)} genes.')\n",
    "    SG_subtypes[k] = list(v)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    allowed_v = [] \n",
    "    plt.plot(df_mean_var['mean'].values)\n",
    "    for sig_gene in v:\n",
    "        sig_gene_idx = np.argwhere(df_mean_var['mean'].index ==sig_gene)[0]\n",
    "        \n",
    "        if sig_gene_idx<= (df_mean_var.shape[0]-50):\n",
    "            plt.axvline(sig_gene_idx,c='g')\n",
    "            allowed_v.append(sig_gene)\n",
    "        else:\n",
    "            plt.axvline(sig_gene_idx,c='r')\n",
    "    SG_subtypes[k] = allowed_v  \n",
    "    plt.xlim([df_mean_var.shape[0]-100,df_mean_var.shape[0]+50])\n",
    "    plt.title(f'avg. expression signature genes for {k}', fontsize=16)\n",
    "    if save:\n",
    "        path = os.path.join(storing_path, 'mean_expr_genes')\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            sc.logging.info(f'Created new directory with path {path}')\n",
    "        plt.savefig(os.path.join(path, f'{k}.png'), format = 'png')\n",
    "    else:\n",
    "        print('not storing image')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in SG_subtypes.items():\n",
    "    print(f'Signature for subtype {k} contains {len(v)} genes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4c2e1e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Use for all signatures the same gene pool create "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6946c9f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_sig_genes = set() \n",
    "for key, val in SG_subtypes.items():\n",
    "    all_sig_genes.update(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca00b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gene_pool = list(set(adata.var_names).difference(all_sig_genes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570405c8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Score  marker genes (differentially expressed genes) for specifc celltypes of level 1 given by the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d76a793",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_bins = 25\n",
    "n_ctrl_genes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e76ee93",
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoring_methods = [\n",
    "    {\n",
    "        \"scoring_method\": \"scanpy_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"ctrl_size\": n_ctrl_genes,\n",
    "            \"n_bins\": n_bins,\n",
    "            \"score_name\": \"Scanpy\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"scoring_method\": \"seurat_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"ctrl_size\": n_ctrl_genes,\n",
    "            \"n_bins\": n_bins,\n",
    "            \"score_name\": \"Seurat\",\n",
    "            \"gene_pool\":gene_pool\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"scoring_method\": \"adjusted_neighborhood_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"ctrl_size\": n_ctrl_genes,\n",
    "            \"score_name\": \"ANS\",\n",
    "            \"gene_pool\":gene_pool\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"scoring_method\": \"seurat_ag_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"n_bins\": n_bins,\n",
    "            \"score_name\": \"Seurat_AG\",\n",
    "            \"gene_pool\":gene_pool\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"scoring_method\": \"seurat_lvg_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"ctrl_size\": n_ctrl_genes,\n",
    "            \"n_bins\": n_bins,\n",
    "            \"lvg_computation_version\": \"v1\",\n",
    "            \"lvg_computation_method\": \"seurat\",\n",
    "            \"score_name\": \"Seurat_LVG\",\n",
    "            \"gene_pool\":gene_pool\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"scoring_method\": \"ucell_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"score_name\": \"UCell\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"scoring_method\": \"jasmine_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"score_method\": 'likelihood',\n",
    "            \"score_name\": \"Jasmine_LH\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"scoring_method\": \"jasmine_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"score_method\": 'oddsratio',\n",
    "            \"score_name\": \"Jasmine_OR\",\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c060d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "method_wo_mean = ['scanpy_scoring', 'corrected_scanpy_scoring','ucell_scoring','jasmine_scoring']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b3130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_names = ['ANS', 'Seurat', 'Seurat_AG', 'Seurat_LVG', 'Scanpy', 'Jasmine_LH', 'Jasmine_OR', 'UCell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a63c64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(set(df_mean_var.index).difference(set(gene_pool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca829c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoring_names = []\n",
    "for sc_method in scoring_methods:\n",
    "    \n",
    "    scoring_method = sc_method['scoring_method']\n",
    "    sc_params = sc_method['sc_params']\n",
    "    \n",
    "    print(f'Running scoring with scoring method {scoring_method}')\n",
    "    \n",
    "    for k1, v1 in SG_subtypes.items():\n",
    "        \n",
    "        print(f'   > Running scoring for signatures of celltyple-l1 {k1}')\n",
    "        \n",
    "        curr_sc_params = sc_params.copy()\n",
    "        curr_sc_params['score_name'] = curr_sc_params['score_name'] +'_'+k1\n",
    "\n",
    "        if scoring_method in method_wo_mean:\n",
    "            score_signature(method=scoring_method,\n",
    "                            adata=adata,\n",
    "                            gene_list=v1,\n",
    "                            **curr_sc_params)\n",
    "        else:\n",
    "            score_signature(method=scoring_method,\n",
    "                        adata=adata,\n",
    "                        gene_list=v1,\n",
    "                        df_mean_var=df_mean_var,\n",
    "                        **curr_sc_params)\n",
    "        scoring_names.append(curr_sc_params['score_name'])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473bf1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoring_names = [x for x in adata.obs.columns if any([y in sc_names or y == 'Jasmine' for y in x.split('_')])]\n",
    "scoring_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b043e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(scoring_names), 3):\n",
    "    gmm_post = GMMPostprocessor(\n",
    "        n_components=3\n",
    "    )\n",
    "    \n",
    "    store_name_pred, store_names_proba, _ = gmm_post.fit_and_predict(adata, scoring_names[i:(i+3)])\n",
    "    assignments = gmm_post.assign_clusters_to_signatures(adata, scoring_names[i:(i+3)], store_names_proba, plot=False)\n",
    "    print(assignments)\n",
    "    for key, val in assignments.items():\n",
    "        adata.obs[key+'_gmm_3K'] = adata.obs[val].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d69cdb7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adata.obs = adata.obs.drop(columns = [x for x in adata.obs.columns if ('_GMM_proba' in x) or ('_GMM_pred' in x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf1f19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoring_names = [x for x in adata.obs.columns if any([y in sc_names or y == 'Jasmine' for y in x.split('_')])]\n",
    "scoring_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15615f22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoring_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806f6ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score_name_wo_gmm = [x for x in scoring_names if 'gmm' not in x]\n",
    "score_name_w_gmm = [x for x in scoring_names if 'gmm_3K' in x]\n",
    "score_name_wo_gmm = sorted(score_name_wo_gmm, key=lambda x: x.rsplit('_', 1)[0])\n",
    "score_name_w_gmm = sorted(score_name_w_gmm, key=lambda x: x.rsplit('_', 3)[0])\n",
    "score_name_wo_gmm, score_name_w_gmm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e026d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### evaluate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216df87f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp = adata.obs[['celltype.l1']+score_name_wo_gmm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ae8963",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp = tmp.melt(id_vars=['celltype.l1'],\n",
    "        var_name='scoring_method',\n",
    "        value_name='scores')\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2025ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.scoring_method.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fdc4c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp['scoring_method_short'] = tmp.scoring_method.apply(lambda x: '_'.join(x.split('_')[0:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec33ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp['Scoring for signature'] = tmp.scoring_method.apply(lambda x: x.split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6147a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['scoring_method_short'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c55c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    fn = os.path.join(storing_path, 'data_for_violin_plot_normal_scores.csv')\n",
    "    tmp.to_csv(fn)\n",
    "    sc.logging.info(f'Storing obs scores at {fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11db4647",
   "metadata": {},
   "outputs": [],
   "source": [
    "order=['B', 'Mono', 'NK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c201edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yticks = [-1, -0.5, 0, 0.5, 1.0]\n",
    "\n",
    "yticks = [round(x,2) for x in yticks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e68406",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.catplot(data=tmp,\n",
    "                x='celltype.l1', \n",
    "                y='scores', \n",
    "                hue='Scoring for signature', \n",
    "                col_order=sc_names,\n",
    "                col= 'scoring_method_short',  \n",
    "                kind='violin', \n",
    "                col_wrap=4,\n",
    "                order=order,\n",
    "                legend=False\n",
    "               )\n",
    "g.set_ylabels('Scores', size=22)\n",
    "g.set_titles(\"{col_name}\", size=24)\n",
    "g.set_xticklabels(order, size=22)\n",
    "g.set(xlabel=None)\n",
    "g.fig.subplots_adjust(top=0.88)\n",
    "g.fig.suptitle('$\\it{Easy}$ task', fontsize=26)\n",
    "g.add_legend(fontsize=22, title='Signature')\n",
    "g.legend.get_title().set_fontsize(22)\n",
    "g.set(yticks=yticks)\n",
    "g.set_yticklabels(yticks, size=20)\n",
    "if save:\n",
    "    plt.savefig(os.path.join(storing_path, 'violin_plots_not_comparable_ranges.svg'), format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e192980",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gt = adata.obs['celltype.l1'].copy()\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d89780",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(adata.obs[['celltype.l1']]).toarray())\n",
    "enc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e21e45",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range(0,len(score_name_wo_gmm),3):\n",
    "    \n",
    "    prediction = adata.obs[score_name_wo_gmm[i:(i+3)]]\n",
    "    \n",
    "#     curr_auc = roc_auc_score(enc_df, prediction, average='weighted')\n",
    "    tmp = prediction.idxmax(axis=1)\n",
    "    tmp[tmp.str.contains('B')] = 'B'\n",
    "    tmp[tmp.str.contains('NK')] = 'NK'\n",
    "    tmp[tmp.str.contains('Mono')] = 'Mono'\n",
    " \n",
    "    curr_f1 = f1_score(gt,tmp, average='weighted')\n",
    "    curr_j = jaccard_score(gt,tmp, average='weighted')\n",
    "    curr_ba = balanced_accuracy_score(gt,tmp)\n",
    "    \n",
    "    row = {\n",
    "        'Scoring method': '_'.join(score_name_wo_gmm[i].split('_')[0:-1]),\n",
    "#         'AUCROC (weighted)':curr_auc,\n",
    "        'F1-score (weighted)':curr_f1, \n",
    "        'Jaccard-score (weighted)':curr_j,\n",
    "        'Balanced accuracy':curr_ba\n",
    "    }\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659f24c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "performance_hard_labeling_on_scores = pd.DataFrame(rows)\n",
    "\n",
    "performance_hard_labeling_on_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb96d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if save:\n",
    "    performance_hard_labeling_on_scores.to_csv(os.path.join(storing_path, 'performance_hard_labeling_on_scores.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece1a427",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "performance_hard_labeling_on_scores = performance_hard_labeling_on_scores.melt(id_vars=['Scoring method', 'F1-score (weighted)'],\n",
    "            var_name='metric',\n",
    "            value_name='met_score'\n",
    ")\n",
    "\n",
    "f = plt.figure(figsize=(8, 6))\n",
    "g = sns.scatterplot(\n",
    "    x='met_score',\n",
    "    y='F1-score (weighted)',\n",
    "    hue='Scoring method',\n",
    "    hue_order=sc_names,\n",
    "    style='metric',\n",
    "    data=performance_hard_labeling_on_scores,\n",
    "    s=200\n",
    ")\n",
    "lgnd = g.legend(bbox_to_anchor=(1, 1), fontsize=16)\n",
    "g.set_title('Performance hard labeling using scores ($\\it{easy}$ task)', fontsize=18)\n",
    "g.set_xlabel('Values of metrics', fontsize=16)\n",
    "g.set_ylabel('F1-score (weighted)', fontsize=16)\n",
    "if save:\n",
    "    f.savefig(os.path.join(storing_path, f'scores_hard_labeling.svg'), format='svg')\n",
    "    f.savefig(os.path.join(storing_path, f'scores_hard_labeling.png'), format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c267a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### evaluate GMM outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952f30a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp = adata.obs[['celltype.l1']+score_name_w_gmm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724868c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp = tmp.melt(id_vars=['celltype.l1'],\n",
    "        var_name='scoring_method',\n",
    "        value_name='scores')\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a95c5e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp['scoring_method_short'] = tmp.scoring_method.apply(lambda x: '_'.join(x.split('_')[0:-3])+' with GMM 3K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d9127",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp['Scoring for signature'] = tmp.scoring_method.apply(lambda x: x.split('_')[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93344a31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp['scoring_method_short'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab5cd1b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp = tmp[tmp.scoring_method_short.str.contains('std_adjust')==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843ba55",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp['scoring_method_short'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b993fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    tmp.to_csv(os.path.join(storing_path, 'data_for_violin_plot_gmm_scores.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b6a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "order=['B', 'Mono', 'NK']\n",
    "yticks = [0, 0.2,0.4,0.6,0.8,1.0]\n",
    "sc_names = ['ANS with GMM 3K', \n",
    "            'Seurat with GMM 3K', \n",
    "            'Seurat_AG with GMM 3K',\n",
    "            'Seurat_LVG with GMM 3K', \n",
    "            'Scanpy with GMM 3K', \n",
    "            'Jasmine_LH with GMM 3K',\n",
    "            'Jasmine_OR with GMM 3K',\n",
    "            'UCell with GMM 3K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd4a95",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.catplot(data=tmp[tmp['scoring_method_short'].str.contains('var adjustment')==False],\n",
    "                x='celltype.l1', \n",
    "                y='scores', \n",
    "                hue='Scoring for signature', \n",
    "                col= 'scoring_method_short', \n",
    "                col_order=sc_names, \n",
    "                kind='violin',\n",
    "                order=order,\n",
    "                #height=10, \n",
    "                #aspect=1\n",
    "               )\n",
    "g.set_ylabels('Scores', size=22)\n",
    "g.set_titles(\"{col_name}\", size=24)\n",
    "g.set_xticklabels(order, size=22)\n",
    "g.set(xlabel=None)\n",
    "# g.add_legend(fontsize=14)\n",
    "g.set(yticks=yticks)\n",
    "g.set_yticklabels(yticks, size=20)\n",
    "if save:\n",
    "    plt.savefig(os.path.join(storing_path, 'violin_plots_not_comparable_ranges_GMM.svg'), format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa14bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gt = adata.obs['celltype.l1'].copy()\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d085c52d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(adata.obs[['celltype.l1']]).toarray())\n",
    "enc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3232039",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score_name_w_gmm = [x for x in score_name_w_gmm if 'std_adjust' not in x]\n",
    "score_name_w_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8df1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range(0,len(score_name_w_gmm),3):\n",
    "    \n",
    "    prediction = adata.obs[score_name_w_gmm[i:(i+3)]]\n",
    "    \n",
    "#     curr_auc = roc_auc_score(enc_df, prediction, average='weighted')\n",
    "    \n",
    "    tmp = prediction.idxmax(axis=1)\n",
    "    tmp[tmp.str.contains('B')] = 'B'\n",
    "    tmp[tmp.str.contains('NK')] = 'NK'\n",
    "    tmp[tmp.str.contains('Mono')] = 'Mono'\n",
    " \n",
    "    curr_f1 = f1_score(gt,tmp, average='weighted')\n",
    "    curr_j = jaccard_score(gt,tmp, average='weighted')\n",
    "    curr_ba = balanced_accuracy_score(gt,tmp)\n",
    "    \n",
    "    row = {\n",
    "        'Scoring method': '_'.join(score_name_w_gmm[i].split('_')[0:-3])+' with GMM 3K',\n",
    "        'F1-score (weighted)':curr_f1, \n",
    "        'Jaccard-score (weighted)':curr_j,\n",
    "        'Balanced accuracy':curr_ba\n",
    "    }\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d29a963",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "performance_hard_labeling_on_scores = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17379e5f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "performance_hard_labeling_on_scores.sort_values(by='Balanced accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05ff9d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if save:\n",
    "    performance_hard_labeling_on_scores.to_csv(os.path.join(storing_path, 'performance_hard_labeling_on_GMM.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f72309",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "performance_hard_labeling_on_scores = performance_hard_labeling_on_scores.melt(id_vars=['Scoring method', 'F1-score (weighted)'],\n",
    "            var_name='metric',\n",
    "            value_name='met_value'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e961a3d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8, 6))\n",
    "g = sns.scatterplot(\n",
    "    x='met_value',\n",
    "    y='F1-score (weighted)',\n",
    "    hue='Scoring method',\n",
    "    hue_order=sc_names,\n",
    "    style='metric',\n",
    "    data=performance_hard_labeling_on_scores,\n",
    "    s=200\n",
    ")\n",
    "lgnd = g.legend(bbox_to_anchor=(1, 1), fontsize=16)\n",
    "g.set_title('Performance hard labeling using probabilities ($\\it{easy}$ task)', fontsize=18)\n",
    "g.set_xlabel('Values of metrics', fontsize=16)\n",
    "g.set_ylabel('F1-score (weighted)', fontsize=16)\n",
    "if save:\n",
    "    f.savefig(os.path.join(storing_path, f'GMM3_hard_labeling.svg'), format='svg')\n",
    "    f.savefig(os.path.join(storing_path, f'GMM3_hard_labeling.png'), format='png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

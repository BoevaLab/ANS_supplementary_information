{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f08c61ab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparable score ranges experiment - *hard* discrimination task\n",
    "The following notebook explores the comparability of score ranges for the *hard* task when using **overlapping** signatures for **all** available B-cell subtypes (B-intermediate, B-memory, B-naive).\n",
    "\n",
    "After selecting the cell type specific signatures we score with each scoring method the signatures and apply hard labeling on the scores as well as on the probabilities returned by the GMM postprocessing.\n",
    "\n",
    "This jupyter notebook uses the data and differentially expressed genes found [here](https://atlas.fredhutch.org/nygc/multimodal-pbmc/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a21a80d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score, jaccard_score, balanced_accuracy_score\n",
    "\n",
    "sys.path.append('../../..')\n",
    "from data.load_data import load_datasets\n",
    "from data.constants import BASE_PATH_DATA, BASE_PATH_EXPERIMENTS\n",
    "\n",
    "from signaturescoring import score_signature\n",
    "from signaturescoring.scoring_methods.gmm_postprocessing import GMMPostprocessor\n",
    "from signaturescoring.utils.utils import check_signature_genes, get_mean_and_variance_gene_expression\n",
    "\n",
    "sc.settings.verbosity = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0bc8a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759053d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'pdf.fonttype':42, 'font.family':'sans-serif', 'font.sans-serif':'Arial', 'font.size':14})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98ad168",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280df055",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the path where the PBMC data is stored\n",
    "dataset = 'pbmc_b_subtypes'\n",
    "norm_method = 'mean'\n",
    "DE_of_celltypes_fn = os.path.join(BASE_PATH_DATA, 'annotations/citeseq_pbmc/DE_by_celltype.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc001e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## define the path where data should be stored.\n",
    "storing_path = os.path.join(BASE_PATH_EXPERIMENTS, 'comparable_score_ranges/B_cell_subtypes/scoring_all_subtypes_overlapping_signautres')\n",
    "if not os.path.exists(storing_path):\n",
    "    os.makedirs(storing_path)\n",
    "    sc.logging.info(f'Created new directory with path {storing_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31692394",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff48dd5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c49d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = load_datasets(dataset, norm_method=norm_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'log1p' in adata.uns_keys():\n",
    "    adata.uns['log1p']['base'] = None\n",
    "else:\n",
    "    adata.uns['log1p'] = {'base': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee18e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['celltype.l2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e643810c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Look at the differentially expressed genes given by the paper\n",
    "The differential gene expression is done on level 3 celltypes. The logfoldchanges for the genes of different cell types are not comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b36caf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## define path to table with DGEX genes\n",
    "DE_of_celltypes = pd.read_csv(DE_of_celltypes_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5184c05",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this part we  want to get signature for a specific celltype (B-cells) of level 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a0705",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subtypes_B = np.unique(DE_of_celltypes[DE_of_celltypes['Cell Type'].str.contains('B ')]['Cell Type'])\n",
    "subtypes_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce505e45",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SG_subtypes_B = {}\n",
    "for subtype in subtypes_B:\n",
    "    SG_subtypes_B[subtype] = list(DE_of_celltypes[DE_of_celltypes['Cell Type']==subtype]['Gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b36c999",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SG_subtypes_B['B intermediate'] = set(SG_subtypes_B['B intermediate kappa']).union(set(SG_subtypes_B['B intermediate lambda']))\n",
    "SG_subtypes_B['B memory'] = set(SG_subtypes_B['B memory kappa']).union(set(SG_subtypes_B['B memory lambda']))\n",
    "SG_subtypes_B['B naive'] = set(SG_subtypes_B['B naive kappa']).union(set(SG_subtypes_B['B naive lambda']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71410161",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for subtype in subtypes_B:\n",
    "    SG_subtypes_B.pop(subtype, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38947f0b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for key, val in SG_subtypes_B.items():\n",
    "    print(f'signature for B-cell subtype {key} has length {len(val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb87dcd9",
   "metadata": {},
   "source": [
    "Check signature genes expressed in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b9bc6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for key, val in SG_subtypes_B.items():\n",
    "    print(f'signature for B-cell subtype {key} has length {len(val)}')\n",
    "    SG_subtypes_B[key]  = check_signature_genes(adata.var_names, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6b978",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_mean_var = get_mean_and_variance_gene_expression(\n",
    "    adata,\n",
    "    estim_var=True,\n",
    "    show_plots=True,\n",
    "    #store_path=storing_path,\n",
    "    #store_data_prefix='all'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353fba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'pdf.fonttype':42, 'font.family':'sans-serif', 'font.sans-serif':'Arial', 'font.size':14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec3c8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for k,v in SG_subtypes_B.items():\n",
    "    print(f'Signature for subtype {k} contains {len(v)} genes.')\n",
    "    SG_subtypes_B[k] = list(v)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    allowed_v = []\n",
    "    plt.plot(df_mean_var['mean'].values)\n",
    "    for sig_gene in v:\n",
    "        sig_gene_idx = np.argwhere(df_mean_var['mean'].index ==sig_gene)[0]\n",
    "        \n",
    "        if sig_gene_idx<= (df_mean_var.shape[0]-50):\n",
    "            plt.axvline(sig_gene_idx,c='g')\n",
    "            allowed_v.append(sig_gene)\n",
    "        else:\n",
    "            plt.axvline(sig_gene_idx,c='r')\n",
    "    SG_subtypes_B[k] = allowed_v  \n",
    "    plt.xlim([df_mean_var.shape[0]-100,df_mean_var.shape[0]+50])\n",
    "    plt.title(f'avg. expression signature genes for {k}')\n",
    "    if save:\n",
    "        path = os.path.join(storing_path, 'mean_expr_genes')\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            sc.logging.info(f'Created new directory with path {path}')\n",
    "        plt.savefig(os.path.join(path, f'{k}.png'), format = 'png')\n",
    "    else:\n",
    "        print('not storing image')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dad32b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for k,v in SG_subtypes_B.items():\n",
    "    print(f'Signature for subtype {k} contains {len(v)} genes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4c2e1e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Use for all signatures the same gene pool create "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6946c9f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_sig_genes = set() \n",
    "for key, val in SG_subtypes_B.items():\n",
    "    all_sig_genes.update(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca00b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gene_pool = list(set(adata.var_names).difference(all_sig_genes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570405c8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Score  marker genes (differentially expressed genes) for specifc celltypes of level2 given by the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d76a793",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_bins = 25\n",
    "n_ctrl_genes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e76ee93",
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoring_methods = [\n",
    "    {\n",
    "        \"scoring_method\": \"scanpy_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"ctrl_size\": n_ctrl_genes,\n",
    "            \"n_bins\": n_bins,\n",
    "            \"score_name\": \"Scanpy\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"scoring_method\": \"seurat_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"ctrl_size\": n_ctrl_genes,\n",
    "            \"n_bins\": n_bins,\n",
    "            \"score_name\": \"Seurat\",\n",
    "            \"gene_pool\":gene_pool\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"scoring_method\": \"adjusted_neighborhood_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"ctrl_size\": n_ctrl_genes,\n",
    "            \"score_name\": \"ANS\",\n",
    "            \"gene_pool\":gene_pool\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"scoring_method\": \"seurat_ag_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"n_bins\": n_bins,\n",
    "            \"score_name\": \"Seurat_AG\",\n",
    "            \"gene_pool\":gene_pool\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"scoring_method\": \"seurat_lvg_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"ctrl_size\": n_ctrl_genes,\n",
    "            \"n_bins\": n_bins,\n",
    "            \"lvg_computation_version\": \"v1\",\n",
    "            \"lvg_computation_method\": \"seurat\",\n",
    "            \"score_name\": \"Seurat_LVG\",\n",
    "            \"gene_pool\":gene_pool\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"scoring_method\": \"ucell_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"score_name\": \"UCell\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"scoring_method\": \"jasmine_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"score_method\": 'likelihood',\n",
    "            \"score_name\": \"Jasmine_LH\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"scoring_method\": \"jasmine_scoring\",\n",
    "        \"sc_params\": {\n",
    "            \"score_method\": 'oddsratio',\n",
    "            \"score_name\": \"Jasmine_OR\",\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c060d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "method_wo_mean = ['scanpy_scoring', 'corrected_scanpy_scoring','ucell_scoring','jasmine_scoring']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e0f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_names = ['ANS', 'Seurat', 'Seurat_AG', 'Seurat_LVG', 'Scanpy', 'Jasmine_LH', 'Jasmine_OR', 'UCell']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3cc5aa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### B-cells and subtypes\n",
    "Here we only score B-cells and signatures that separate subtypes of B-cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a63c64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(set(df_mean_var.index).difference(set(gene_pool))), len(gene_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca829c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoring_names = []\n",
    "for sc_method in scoring_methods:\n",
    "    \n",
    "    scoring_method = sc_method['scoring_method']\n",
    "    sc_params = sc_method['sc_params']\n",
    "    \n",
    "    print(f'Running scoring with scoring method {scoring_method}')\n",
    "    \n",
    "    for k1, v1 in SG_subtypes_B.items():\n",
    "        print(f'   > Running scoring for signatures of celltyple-l2 {k1}')\n",
    "        \n",
    "        curr_sc_params = sc_params.copy()\n",
    "        curr_sc_params['score_name'] = curr_sc_params['score_name'] +'_'+k1\n",
    "\n",
    "        if scoring_method in method_wo_mean:\n",
    "            score_signature(method=scoring_method,\n",
    "                            adata=adata,\n",
    "                            gene_list=v1,\n",
    "                            **curr_sc_params)\n",
    "        else:\n",
    "            score_signature(method=scoring_method,\n",
    "                        adata=adata,\n",
    "                        gene_list=v1,\n",
    "                        df_mean_var=df_mean_var,\n",
    "                        **curr_sc_params)\n",
    "        scoring_names.append(curr_sc_params['score_name'])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d566e62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# adata.obs.to_csv(os.path.join(storing_path, 'adata_obs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6389d63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# adata_obs = pd.read_csv(os.path.join(storing_path, 'adata_obs.csv'))\n",
    "\n",
    "# adata_obs = adata_obs.set_index('Unnamed: 0')\n",
    "# adata_obs.index.name = None\n",
    "# adata_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c304a27",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# adata.obs = adata_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473bf1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoring_names = [x for x in adata.obs.columns if any([y in sc_names or y == 'Jasmine' for y in x.split('_')])]\n",
    "scoring_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b043e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(scoring_names), 3):\n",
    "    gmm_post = GMMPostprocessor(\n",
    "        n_components=3\n",
    "    )\n",
    "    \n",
    "    store_name_pred, store_names_proba, _ = gmm_post.fit_and_predict(adata, scoring_names[i:(i+3)])\n",
    "    assignments = gmm_post.assign_clusters_to_signatures(adata, scoring_names[i:(i+3)], store_names_proba, plot=False)\n",
    "    print(assignments)\n",
    "    for key, val in assignments.items():\n",
    "        if key == 'rest':\n",
    "            print(f'Couldn\\'t could find correct GMM cluster and signature mapping. Skipping {scoring_names[i:(i+3)]} is adviced')\n",
    "            continue\n",
    "        adata.obs[key+'_gmm_3K'] = adata.obs[val].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc53db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def _plot_score_pca(sc_method_name):\n",
    "    pca = PCA(n_components=2)\n",
    "    PCS = pca.fit_transform(adata.obs[[f'{sc_method_name}_B naive',\n",
    "                      f'{sc_method_name}_B intermediate',\n",
    "                      f'{sc_method_name}_B memory']])\n",
    "\n",
    "    plt.scatter(x=PCS[:,0], y=PCS[:,1], c=adata.obs[f'{sc_method_name}_B 0_GMM_proba'], alpha=0.5)\n",
    "    plt.title(f'{sc_method_name}_B 0_GMM_proba');\n",
    "    plt.show()\n",
    "    plt.scatter(x=PCS[:,0], y=PCS[:,1], c=adata.obs[f'{sc_method_name}_B 1_GMM_proba'], alpha=0.5)\n",
    "    plt.title(f'{sc_method_name}_B 1_GMM_proba');\n",
    "    plt.show()\n",
    "    plt.scatter(x=PCS[:,0], y=PCS[:,1], c=adata.obs[f'{sc_method_name}_B 2_GMM_proba'], alpha=0.5)\n",
    "    plt.title(f'{sc_method_name}_B 2_GMM_proba');\n",
    "    plt.show()\n",
    "    plt.scatter(x=PCS[:,0], y=PCS[:,1], c=['green' if x =='B naive' else ('blue' if x=='B intermediate' else 'orange')for x in adata.obs['celltype.l2']], alpha=0.5)\n",
    "    plt.title('celltype.l2');\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "_plot_score_pca('Jasmine_LH') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda64aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_score_pca('Jasmine_OR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b77a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['Jasmine_LH_B intermediate_gmm_3K'] = adata.obs['Jasmine_LH_B 1_GMM_proba'].copy()\n",
    "adata.obs['Jasmine_LH_B memory_gmm_3K'] = adata.obs['Jasmine_LH_B 1_GMM_proba'].copy()\n",
    "adata.obs['Jasmine_LH_B naive_gmm_3K'] = adata.obs['Jasmine_LH_B 2_GMM_proba'].copy()\n",
    "\n",
    "\n",
    "adata.obs['Jasmine_OR_B intermediate_gmm_3K'] = adata.obs['Jasmine_OR_B 2_GMM_proba'].copy()\n",
    "adata.obs['Jasmine_OR_B memory_gmm_3K'] = adata.obs['Jasmine_OR_B 0_GMM_proba'].copy()\n",
    "adata.obs['Jasmine_OR_B naive_gmm_3K'] = adata.obs['Jasmine_OR_B 2_GMM_proba'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d69cdb7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adata.obs = adata.obs.drop(columns = [x for x in adata.obs.columns if ('_GMM_proba' in x) or ('_GMM_pred' in x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf1f19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoring_names = [x for x in adata.obs.columns if any([y in sc_names or y == 'Jasmine' for y in x.split('_')])]\n",
    "scoring_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15615f22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoring_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806f6ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score_name_wo_gmm = [x for x in scoring_names if 'gmm' not in x]\n",
    "score_name_w_gmm = [x for x in scoring_names if 'gmm_3K' in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383471d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### evaluate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216df87f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp = adata.obs[['celltype.l2']+score_name_wo_gmm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ae8963",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp = tmp.melt(id_vars=['celltype.l2'],\n",
    "        var_name='scoring_method',\n",
    "        value_name='scores')\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43aa661",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tmp = tmp.groupby(by=['celltype.l2', 'scoring_method']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fdc4c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp['scoring_method_short'] = tmp.scoring_method.apply(lambda x: '_'.join(x.split('_')[0:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec33ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp['Scoring for signature'] = tmp.scoring_method.apply(lambda x: x.split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a91a43",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp['scoring_method_short'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a47064",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    tmp.to_csv(os.path.join(storing_path, 'data_for_violin_plot_normal_scores.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf47500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "order=['B naive', 'B intermediate', 'B memory']\n",
    "\n",
    "sc_names = ['ANS', 'Seurat', 'Seurat_AG', 'Seurat_LVG', 'Scanpy', 'Jasmine_LH', 'Jasmine_OR', 'UCell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743289ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "yticks = [-1, -0.5, 0, 0.5, 1.0, 1.5]\n",
    "\n",
    "yticks = [round(x,2) for x in yticks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04cffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "def wrap_labels(ax, width, break_long_words=False):\n",
    "    labels = []\n",
    "    for label in ax.get_xticklabels():\n",
    "        text = label.get_text()\n",
    "        labels.append(textwrap.fill(text, width=width,\n",
    "                      break_long_words=break_long_words))\n",
    "    ax.set_xticklabels(labels, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b52f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(data=tmp,\n",
    "                x='celltype.l2', \n",
    "                y='scores', \n",
    "                hue='Scoring for signature', \n",
    "                hue_order=order,\n",
    "                col_order=sc_names,\n",
    "                col= 'scoring_method_short',  \n",
    "                kind='violin', \n",
    "                col_wrap=4,\n",
    "                order=order,\n",
    "                legend=False\n",
    "               )\n",
    "g.set_ylabels('Scores', size=22)\n",
    "g.set_titles(\"{col_name}\", size=24)\n",
    "g.set_xticklabels(order, size=22)\n",
    "g.set(xlabel=None)\n",
    "g.fig.subplots_adjust(top=0.88)\n",
    "g.fig.suptitle('$\\it{Hard}$ task', fontsize=26)\n",
    "g.add_legend(fontsize=22, title='Signature')\n",
    "g.legend.get_title().set_fontsize(22)\n",
    "g.set(yticks=yticks)\n",
    "g.set_yticklabels(yticks, size=20)\n",
    "\n",
    "for ax in g.axes[4:]:\n",
    "    wrap_labels(ax, 7, break_long_words=True)\n",
    "\n",
    "if save:\n",
    "    plt.savefig(os.path.join(storing_path, 'violin_plots_not_comparable_ranges.svg'), format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84af204",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gt = adata.obs['celltype.l2'].copy()\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab294c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(adata.obs[['celltype.l2']]).toarray())\n",
    "enc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f2fe5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range(0,len(score_name_wo_gmm),3):\n",
    "    \n",
    "    prediction = adata.obs[score_name_wo_gmm[i:(i+3)]]\n",
    "    \n",
    "#     curr_auc = roc_auc_score(enc_df, prediction, average='weighted')\n",
    "    \n",
    "    tmp = prediction.idxmax(axis=1)\n",
    "    tmp[tmp.str.contains('B memory')] = 'B memory'\n",
    "    tmp[tmp.str.contains('B naive')] = 'B naive'\n",
    "    tmp[tmp.str.contains('B intermediate')] = 'B intermediate'\n",
    " \n",
    "    curr_f1 = f1_score(gt,tmp, average='weighted')\n",
    "    curr_j = jaccard_score(gt,tmp, average='weighted')\n",
    "    curr_ba = balanced_accuracy_score(gt,tmp)\n",
    "    \n",
    "    row = {\n",
    "        'Scoring method': '_'.join(score_name_wo_gmm[i].split('_')[0:-1]),\n",
    "#         'AUCROC (weighted)':curr_auc,\n",
    "        'F1-score (weighted)':curr_f1, \n",
    "        'Jaccard-score (weighted)':curr_j,\n",
    "        'Balanced accuracy':curr_ba\n",
    "    }\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a121593c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "performance_hard_labeling_on_scores = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb96d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if save:\n",
    "    performance_hard_labeling_on_scores.to_csv(os.path.join(storing_path, 'performance_hard_labeling_on_scores.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece1a427",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "performance_hard_labeling_on_scores = performance_hard_labeling_on_scores.melt(id_vars=['Scoring method', 'F1-score (weighted)'],\n",
    "            var_name='metric',\n",
    "            value_name='value'\n",
    ")\n",
    "\n",
    "f = plt.figure(figsize=(8, 6))\n",
    "g = sns.scatterplot(\n",
    "    x='value',\n",
    "    y='F1-score (weighted)',\n",
    "    hue='Scoring method',\n",
    "    hue_order=sc_names, \n",
    "    style='metric',\n",
    "    data=performance_hard_labeling_on_scores,\n",
    "    s=200\n",
    ")\n",
    "lgnd = g.legend(bbox_to_anchor=(1, 1), fontsize=16)\n",
    "g.set_title('Performance hard labeling using scores ($\\it{hard}$ task)', fontsize=18)\n",
    "g.set_xlabel('Values of metrics', fontsize=16)\n",
    "g.set_ylabel('F1-score (weighted)', fontsize=16)\n",
    "if save:\n",
    "    f.savefig(os.path.join(storing_path, f'scores_hard_labeling.svg'), format='svg')\n",
    "    f.savefig(os.path.join(storing_path, f'scores_hard_labeling.png'), format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d73f20",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### evaluate GMM outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952f30a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp = adata.obs[['celltype.l2']+score_name_w_gmm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724868c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp = tmp.melt(id_vars=['celltype.l2'],\n",
    "        var_name='scoring_method',\n",
    "        value_name='scores')\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a95c5e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp['scoring_method_short'] = tmp.scoring_method.apply(lambda x: '_'.join(x.split('_')[0:-3])+' with GMM 3K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d9127",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp['Scoring for signature'] = tmp.scoring_method.apply(lambda x: x.split('_')[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93344a31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp['scoring_method_short'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d3d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    tmp.to_csv(os.path.join(storing_path, 'data_for_violin_plot_gmm_scores.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa68a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "yticks = [0, 0.2,0.4,0.6,0.8,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecfaa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_names = ['ANS with GMM 3K', 'Seurat with GMM 3K',\n",
    "            'Seurat_AG with GMM 3K', 'Seurat_LVG with GMM 3K',\n",
    "            'Scanpy with GMM 3K', 'Jasmine_LH with GMM 3K',\n",
    "            'Jasmine_OR with GMM 3K','UCell with GMM 3K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd6136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(data=tmp[tmp['scoring_method_short'].str.contains('var adjustment')==False],\n",
    "                x='celltype.l2', \n",
    "                y='scores', \n",
    "                hue='Scoring for signature', \n",
    "                hue_order=order,\n",
    "                col= 'scoring_method_short', \n",
    "                col_order=sc_names, \n",
    "                kind='violin',\n",
    "                order=order,\n",
    "                #height=10, \n",
    "                #aspect=1\n",
    "               )\n",
    "g.set_ylabels('Scores', size=22)\n",
    "g.set_titles(\"{col_name}\", size=24)\n",
    "g.set_xticklabels(order, size=22)\n",
    "g.set(xlabel=None)\n",
    "g.set(yticks=yticks)\n",
    "g.set_yticklabels(yticks, size=20)\n",
    "for ax in g.axes[0]:\n",
    "    wrap_labels(ax, 7, break_long_words=True)\n",
    "if save:\n",
    "    plt.savefig(os.path.join(storing_path, 'violin_plots_not_comparable_ranges_GMM.svg'), format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa14bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gt = adata.obs['celltype.l2'].copy()\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d085c52d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(adata.obs[['celltype.l2']]).toarray())\n",
    "enc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3232039",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score_name_w_gmm = [x for x in score_name_w_gmm if 'std_adjust' not in x]\n",
    "score_name_w_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8df1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range(0,len(score_name_w_gmm),3):\n",
    "    \n",
    "    prediction = adata.obs[score_name_w_gmm[i:(i+3)]]\n",
    "    \n",
    "#     curr_auc = roc_auc_score(enc_df, prediction, average='weighted')\n",
    "    \n",
    "    tmp = prediction.idxmax(axis=1)\n",
    "    tmp[tmp.str.contains('B memory')] = 'B memory'\n",
    "    tmp[tmp.str.contains('B naive')] = 'B naive'\n",
    "    tmp[tmp.str.contains('B intermediate')] = 'B intermediate'\n",
    " \n",
    "    curr_f1 = f1_score(gt,tmp, average='weighted')\n",
    "    curr_j = jaccard_score(gt,tmp, average='weighted')\n",
    "    curr_ba = balanced_accuracy_score(gt,tmp)\n",
    "    \n",
    "    row = {\n",
    "        'Scoring method': '_'.join(score_name_w_gmm[i].split('_')[0:-3])+' with GMM 3K',\n",
    "#         'AUCROC (weighted)':curr_auc,\n",
    "        'F1-score (weighted)':curr_f1, \n",
    "        'Jaccard-score (weighted)':curr_j,\n",
    "        'Balanced accuracy':curr_ba\n",
    "    }\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d29a963",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "performance_hard_labeling_on_scores = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17379e5f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "performance_hard_labeling_on_scores.sort_values(by='Balanced accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05ff9d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if save:\n",
    "    performance_hard_labeling_on_scores.to_csv(os.path.join(storing_path, 'performance_hard_labeling_on_GMM.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f72309",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "performance_hard_labeling_on_scores = performance_hard_labeling_on_scores.melt(id_vars=['Scoring method', 'F1-score (weighted)'],\n",
    "            var_name='metric',\n",
    "            value_name='value'\n",
    ")\n",
    "performance_hard_labeling_on_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e961a3d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8, 6))\n",
    "g = sns.scatterplot(\n",
    "    x='value',\n",
    "    y='F1-score (weighted)',\n",
    "    hue='Scoring method',\n",
    "    hue_order=sc_names,\n",
    "    style='metric',\n",
    "    data=performance_hard_labeling_on_scores,\n",
    "    s=200\n",
    ")\n",
    "lgnd = g.legend(bbox_to_anchor=(1, 1), fontsize=16)\n",
    "g.set_title('Performance hard labeling using probabilities ($\\it{hard}$ task)', fontsize=18)\n",
    "g.set_xlabel('Values of metrics', fontsize=16)\n",
    "g.set_ylabel('F1-score (weighted)', fontsize=16)\n",
    "if save:\n",
    "    f.savefig(os.path.join(storing_path, f'GMM3_hard_labeling.svg'), format='svg')\n",
    "    f.savefig(os.path.join(storing_path, f'GMM3_hard_labeling.png'), format='png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
